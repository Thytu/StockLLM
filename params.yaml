general:
  project-name: &project_name StockLLM


model: &model

  model_max_length: &model_max_length 2048

  bitesandbytes_parameters:
    load_in_4bit: True
    bnb_4bit_use_double_quant: True
    bnb_4bit_quant_type: nf4
    bnb_4bit_compute_dtype: bfloat16


training:
  train_batch_size: &train_batch_size 16
  eval_batch_size: &eval_batch_size 16
  use_bf16: &use_bf16 False
  optimizer: &optimizer paged_adamw_8bit

stages:

  create-task-find-last-move:
    module: "tasks.create_task_find_last_move"
    params:
      number_of_samples: 15000
      path_to_output_dataset: "outputs/tasks/findLastMove.parquet"

  create-task-find-score:
    module: "tasks.create_task_find_score"
    params:
      number_of_samples: 20000
      path_to_output_dataset: "outputs/tasks/findScore.parquet"

  create-task-MLM-on-moves:
    module: "tasks.create_task_MLM_on_moves"
    params:
      number_of_samples: 15000
      path_to_output_dataset: "outputs/tasks/MLM.parquet"

  create-task-find-who-is-winning:
    module: "tasks.create_task_find_who_is_winning"
    params:
      number_of_samples: 20000
      path_to_output_dataset: "outputs/tasks/whoIsWinning.parquet"

  create-task-sort-FENs:
    module: "tasks.create_task_sort_FENs"
    params:
      number_of_samples: 10000
      path_to_output_dataset: "outputs/tasks/sortFENs.parquet"

  create-task-find-next-best-move:
    module: "tasks.create_task_find_next_best_move"
    params:
      number_of_samples: 20000
      path_to_output_dataset: "outputs/tasks/bestMove.parquet"

  merge-tasks-into-dataset:
    module: "data_processing.merge_tasks_into_dataset"
    params:
      paths:
        - "outputs/tasks/findLastMove.parquet"
        - "outputs/tasks/findScore.parquet"
        - "outputs/tasks/MLM.parquet"
        - "outputs/tasks/whoIsWinning.parquet"
        - "outputs/tasks/sortFENs.parquet"
        - "outputs/tasks/bestMove.parquet"
      test_size: 0.01
      path_to_train_set: "outputs/raw/train.csv"
      path_to_test_set: "outputs/raw/test.csv"

  train-poc:
    module: "training.train"
    params:
      path_to_outputs: "outputs/poc/"
      project_name: *project_name
      model_parameters: *model
      training_parameters:
        max_steps: 650
        warmup_steps: 3
        eval_steps: 25
        save_steps: 50
        logging_steps: 50
        model_max_length: &poc_model_max_length 1024
        per_device_train_batch_size: *train_batch_size
        per_device_eval_batch_size: *eval_batch_size

  generate-poc-dataset:
    module: "data_processing.generate_ready_to_use_dataset"
    params:
      path_to_test_set: "outputs/raw/test.csv"
      path_to_train_set: "outputs/raw/train.csv"
      path_to_output_dataset: "outputs/poc-dataset/"
      model_max_length: *poc_model_max_length

  generate-final-dataset:
    module: "data_processing.generate_ready_to_use_dataset"
    params:
      path_to_test_set: "outputs/raw/test.csv"
      path_to_train_set: "outputs/raw/train.csv"
      path_to_output_dataset: "outputs/poc-dataset/"
      model_max_length: *model_max_length

  train-final-model:
    module: "training.train"
    params:
      path_to_outputs: "outputs/model/"
      project_name: *project_name
      model_parameters: *model
      training_parameters:
        max_steps: 10_000
        warmup_steps: 5
        eval_steps: 100
        save_steps: 200
        logging_steps: 200
        model_max_length: *model_max_length
        per_device_train_batch_size: *train_batch_size
        per_device_eval_batch_size: *eval_batch_size
        gradient_accumulation_steps: 2
